{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopword_tokenized</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>basherrl heh kontol jan sok pemes kamu di rp m...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...</td>\n",
       "      <td>['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...</td>\n",
       "      <td>basherrl heh kontol jan sok pemes rp muka kek ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>kontol mana kontol memek ganas mencari im comi...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['kontol', 'mana', 'kontol', 'memek', 'ganas',...</td>\n",
       "      <td>['kontol', 'kontol', 'memek', 'ganas', 'mencar...</td>\n",
       "      <td>kontol kontol memek ganas mencari im coming ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666</td>\n",
       "      <td>quoteadopt rapeafaacebbpatahkan kntolnyann mad...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...</td>\n",
       "      <td>['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...</td>\n",
       "      <td>quoteadopt rapeafaacebbpatahkan kntolnyann mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>626</td>\n",
       "      <td>ihh badan nya laki banget ya apalagi pantat pa...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['ihh', 'badan', 'nya', 'laki', 'banget', 'ya'...</td>\n",
       "      <td>['ihh', 'badan', 'laki', 'banget', 'pantat', '...</td>\n",
       "      <td>ihh badan laki banget pantat paha kakinya upps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490</td>\n",
       "      <td>smuterpe srp ngghh aghh fasterr pleasehh entot...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...</td>\n",
       "      <td>['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...</td>\n",
       "      <td>smuterpe srp ngghh aghh fasterr pleasehh entot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      original_text     source  \\\n",
       "0          98  basherrl heh kontol jan sok pemes kamu di rp m...    twitter   \n",
       "1         272  kontol mana kontol memek ganas mencari im comi...    twitter   \n",
       "2         666  quoteadopt rapeafaacebbpatahkan kntolnyann mad...     kaskus   \n",
       "3         626  ihh badan nya laki banget ya apalagi pantat pa...  instagram   \n",
       "4         490  smuterpe srp ngghh aghh fasterr pleasehh entot...    twitter   \n",
       "\n",
       "   pornografi  sara  radikalisme  pencemaran_nama_baik  \\\n",
       "0           1     0            0                     1   \n",
       "1           1     0            0                     0   \n",
       "2           1     0            0                     0   \n",
       "3           1     0            0                     1   \n",
       "4           1     0            0                     0   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  ['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...   \n",
       "1  ['kontol', 'mana', 'kontol', 'memek', 'ganas',...   \n",
       "2  ['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...   \n",
       "3  ['ihh', 'badan', 'nya', 'laki', 'banget', 'ya'...   \n",
       "4  ['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...   \n",
       "\n",
       "                                  stopword_tokenized  \\\n",
       "0  ['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...   \n",
       "1  ['kontol', 'kontol', 'memek', 'ganas', 'mencar...   \n",
       "2  ['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...   \n",
       "3  ['ihh', 'badan', 'laki', 'banget', 'pantat', '...   \n",
       "4  ['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  basherrl heh kontol jan sok pemes rp muka kek ...  \n",
       "1  kontol kontol memek ganas mencari im coming ba...  \n",
       "2  quoteadopt rapeafaacebbpatahkan kntolnyann mad...  \n",
       "3  ihh badan laki banget pantat paha kakinya upps...  \n",
       "4  smuterpe srp ngghh aghh fasterr pleasehh entot...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/selected_samples.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    \"kntl\": \"kontol\",\n",
    "    \"yg\": \"yang\",\n",
    "    \"udh\": \"sudah\",\n",
    "    \"tdk\": \"tidak\",\n",
    "    \"jgn\": \"jangan\",\n",
    "    \"trus\": \"terus\",\n",
    "    \"krn\": \"karena\",\n",
    "    \"hrs\": \"harus\",\n",
    "    \"blm\": \"belum\",\n",
    "    \"bs\": \"bisa\",\n",
    "    \"aja\": \"saja\",\n",
    "    \"sm\": \"sama\",\n",
    "    \"dgn\": \"dengan\",\n",
    "    \"utk\": \"untuk\",\n",
    "    \"bgt\": \"banget\",\n",
    "    \"jg\": \"juga\",\n",
    "    \"dlm\": \"dalam\",\n",
    "    \"ttg\": \"tentang\",\n",
    "    \"pd\": \"pada\",\n",
    "    \"lbh\": \"lebih\",\n",
    "    \"dr\": \"dari\",\n",
    "    \"tp\": \"tapi\",\n",
    "    \"yg\": \"yang\",\n",
    "    \"gk\": \"gak\",\n",
    "    \"ga\": \"gak\",\n",
    "    \"lu\": \"kamu\",\n",
    "    \"gw\": \"saya\",\n",
    "    \"sih\": \"sih\",\n",
    "    \"dong\": \"dong\",\n",
    "    \"deh\": \"deh\",\n",
    "    \"nih\": \"nih\",\n",
    "    \"loh\": \"loh\",\n",
    "    \"koq\": \"kok\",\n",
    "    \"yuk\": \"ayo\",\n",
    "    \"biar\": \"biar\",\n",
    "    \"gitu\": \"begitu\",\n",
    "    \"kalo\": \"kalau\",\n",
    "    \"kenapa\": \"mengapa\",\n",
    "    \"si\": \"si\",\n",
    "    \"nya\": \"nya\",\n",
    "    \"cuy\": \"teman\",\n",
    "    \"bro\": \"teman\",\n",
    "    \"sis\": \"teman\",\n",
    "    \"fotoin\": \"foto\",\n",
    "    \"bales\": \"balas\",\n",
    "    \"pe\": \"per\",\n",
    "    \"ye\": \"ya\",\n",
    "    \"lg\": \"lagi\",\n",
    "    \"liat\": \"lihat\",\n",
    "    \"pake\": \"pakai\",\n",
    "    \"knp\": \"kenapa\",\n",
    "    \"oke\": \"ok\",\n",
    "    \"thx\": \"terima kasih\",\n",
    "    \"pls\": \"tolong\",\n",
    "    \"tq\": \"terima kasih\",\n",
    "    \"sorry\": \"maaf\",\n",
    "    \"btw\": \"ngomong-ngomong\",\n",
    "    \"fyi\": \"untuk informasi Anda\",\n",
    "    \"lol\": \"tertawa\",\n",
    "    \"rofl\": \"tertawa\",\n",
    "    \"lmao\": \"tertawa\",\n",
    "    \"omg\": \"ya Tuhan\",\n",
    "    \"wkwk\": \"tertawa\",\n",
    "    \"hehe\": \"tertawa\",\n",
    "    \"haha\": \"tertawa\",\n",
    "    \"cmiiw\": \"kalau saya tidak salah\",\n",
    "    \"imo\": \"menurut saya\",\n",
    "    \"imho\": \"menurut saya\",\n",
    "    \"asap\": \"secepatnya\",\n",
    "    \"fml\": \"sialan hidupku\",\n",
    "    \"idk\": \"saya tidak tahu\",\n",
    "    \"irl\": \"dalam kehidupan nyata\",\n",
    "    \"tho\": \"walaupun\",\n",
    "    \"tbh\": \"sejujurnya\",\n",
    "    \"smh\": \"menggelengkan kepala\",\n",
    "    \"afaik\": \"sepengetahuan saya\",\n",
    "    \"brb\": \"sebentar\",\n",
    "    \"bfn\": \"sampai nanti\",\n",
    "    \"ttyl\": \"nanti kita bicara lagi\",\n",
    "    \"gtg\": \"harus pergi\",\n",
    "    \"icymi\": \"kalau Anda ketinggalan\",\n",
    "    \"nsfw\": \"tidak aman untuk dilihat di tempat kerja\",\n",
    "    \"nvm\": \"tidak apa-apa\",\n",
    "    \"yolo\": \"hidup hanya sekali\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopword_tokenized</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>basherrl heh kontol jan sok pemes kamu di rp m...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...</td>\n",
       "      <td>['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...</td>\n",
       "      <td>basherrl heh kontol jan sok pemes rp muka kek ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>kontol mana kontol memek ganas mencari im comi...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['kontol', 'mana', 'kontol', 'memek', 'ganas',...</td>\n",
       "      <td>['kontol', 'kontol', 'memek', 'ganas', 'mencar...</td>\n",
       "      <td>kontol kontol memek ganas mencari im coming ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666</td>\n",
       "      <td>quoteadopt rapeafaacebbpatahkan kntolnyann mad...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...</td>\n",
       "      <td>['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...</td>\n",
       "      <td>quoteadopt rapeafaacebbpatahkan kntolnyann mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>626</td>\n",
       "      <td>ihh badan nya laki banget ya apalagi pantat pa...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['ihh', 'badan', 'nya', 'laki', 'banget', 'ya'...</td>\n",
       "      <td>['ihh', 'badan', 'laki', 'banget', 'pantat', '...</td>\n",
       "      <td>ihh badan laki banget pantat paha kakinya upps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>490</td>\n",
       "      <td>smuterpe srp ngghh aghh fasterr pleasehh entot...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...</td>\n",
       "      <td>['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...</td>\n",
       "      <td>smuterpe srp ngghh aghh fasterr pleasehh entot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      original_text     source  \\\n",
       "0          98  basherrl heh kontol jan sok pemes kamu di rp m...    twitter   \n",
       "1         272  kontol mana kontol memek ganas mencari im comi...    twitter   \n",
       "2         666  quoteadopt rapeafaacebbpatahkan kntolnyann mad...     kaskus   \n",
       "3         626  ihh badan nya laki banget ya apalagi pantat pa...  instagram   \n",
       "4         490  smuterpe srp ngghh aghh fasterr pleasehh entot...    twitter   \n",
       "\n",
       "   pornografi  sara  radikalisme  pencemaran_nama_baik  \\\n",
       "0           1     0            0                     1   \n",
       "1           1     0            0                     0   \n",
       "2           1     0            0                     0   \n",
       "3           1     0            0                     1   \n",
       "4           1     0            0                     0   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  ['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...   \n",
       "1  ['kontol', 'mana', 'kontol', 'memek', 'ganas',...   \n",
       "2  ['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...   \n",
       "3  ['ihh', 'badan', 'nya', 'laki', 'banget', 'ya'...   \n",
       "4  ['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...   \n",
       "\n",
       "                                  stopword_tokenized  \\\n",
       "0  ['basherrl', 'heh', 'kontol', 'jan', 'sok', 'p...   \n",
       "1  ['kontol', 'kontol', 'memek', 'ganas', 'mencar...   \n",
       "2  ['quoteadopt', 'rapeafaacebbpatahkan', 'kntoln...   \n",
       "3  ['ihh', 'badan', 'laki', 'banget', 'pantat', '...   \n",
       "4  ['smuterpe', 'srp', 'ngghh', 'aghh', 'fasterr'...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  basherrl heh kontol jan sok pemes rp muka kek ...  \n",
       "1  kontol kontol memek ganas mencari im coming ba...  \n",
       "2  quoteadopt rapeafaacebbpatahkan kntolnyann mad...  \n",
       "3  ihh badan laki banget pantat paha kakinya upps...  \n",
       "4  smuterpe srp ngghh aghh fasterr pleasehh entot...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def case_folding(text):\n",
    "    # Melakukan Permbersihan data menggunakan teknik Re \n",
    "    text = re.sub(r'[|?|$|.|!_:\")(-+,)]',' ', text) # Menghilangkan symbol\n",
    "    text = text.translate(str.maketrans(' ',' ',string.punctuation)) # Menghilangkan Punctuation\n",
    "    text = re.sub(r'\\d+', '', text) # Menghilangkan angka\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # Menghilangkan karakter non-alfabetik kecuali spasi dan karakter khusus dalam kata\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Menghilangkan spasi berlebih\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text)  # Mengurangi pengulangan karakter\n",
    "    text = ' '.join([abbreviations.get(word, word) for word in text.split()])  # Mengganti singkatan\n",
    "   \n",
    "    # Menghilangkan RT, mention, dan URL\n",
    "    text = re.sub(r'RT\\s', '', text)  # Menghilangkan RT\n",
    "    text = re.sub(r'@\\w+', '', text)  # Menghilangkan mentions\n",
    "    text = re.sub(r'http\\S+', '', text)  # Menghilangkan URL\n",
    "    # Mengganti kata menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "\n",
    "    \n",
    "\n",
    "    return text\n",
    "\n",
    "df['original_text'] = df['original_text'].apply(case_folding)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>original_text</th>\n",
       "      <th>source</th>\n",
       "      <th>pornografi</th>\n",
       "      <th>sara</th>\n",
       "      <th>radikalisme</th>\n",
       "      <th>pencemaran_nama_baik</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stopword_tokenized</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>665</td>\n",
       "      <td>di arab modernisasi ulama dan provokator sara ...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['di', 'arab', 'modernisasi', 'ulama', 'dan', ...</td>\n",
       "      <td>['arab', 'modernisasi', 'ulama', 'provokator',...</td>\n",
       "      <td>arab modernisasi ulama provokator sara tahan g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>100</td>\n",
       "      <td>ah in ma sinetron kejar tayang nanti ad istila...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['ah', 'in', 'ma', 'sinetron', 'kejar', 'tayan...</td>\n",
       "      <td>['ah', 'in', 'ma', 'sinetron', 'kejar', 'tayan...</td>\n",
       "      <td>ah in ma sinetron kejar tayang ad istilah gant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>567</td>\n",
       "      <td>mampus kamu admin goblok kebanyakan micin nang...</td>\n",
       "      <td>instagram</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['mampus', 'kamu', 'admin', 'goblok', 'kebanya...</td>\n",
       "      <td>['mampus', 'admin', 'goblok', 'kebanyakan', 'm...</td>\n",
       "      <td>mampus admin goblok kebanyakan micin nangis da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>484</td>\n",
       "      <td>quoteremayaadeecbnnlu yang bego bong saya gak ...</td>\n",
       "      <td>kaskus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>['quoteremayaadeecbnnlu', 'yang', 'bego', 'bon...</td>\n",
       "      <td>['quoteremayaadeecbnnlu', 'bego', 'bong', 'gak...</td>\n",
       "      <td>quoteremayaadeecbnnlu bego bong gak bilang aho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>218</td>\n",
       "      <td>astaghfirullooh ngikut sunnah dianggap tolol a...</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['astaghfirullooh', 'ngikut', 'sunnah', 'diang...</td>\n",
       "      <td>['astaghfirullooh', 'ngikut', 'sunnah', 'diang...</td>\n",
       "      <td>astaghfirullooh ngikut sunnah dianggap tolol a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                      original_text     source  \\\n",
       "195         665  di arab modernisasi ulama dan provokator sara ...    twitter   \n",
       "196         100  ah in ma sinetron kejar tayang nanti ad istila...    twitter   \n",
       "197         567  mampus kamu admin goblok kebanyakan micin nang...  instagram   \n",
       "198         484  quoteremayaadeecbnnlu yang bego bong saya gak ...     kaskus   \n",
       "199         218  astaghfirullooh ngikut sunnah dianggap tolol a...    twitter   \n",
       "\n",
       "     pornografi  sara  radikalisme  pencemaran_nama_baik  \\\n",
       "195           0     1            1                     1   \n",
       "196           0     0            1                     1   \n",
       "197           0     0            0                     1   \n",
       "198           0     0            0                     1   \n",
       "199           0     1            1                     1   \n",
       "\n",
       "                                        tokenized_text  \\\n",
       "195  ['di', 'arab', 'modernisasi', 'ulama', 'dan', ...   \n",
       "196  ['ah', 'in', 'ma', 'sinetron', 'kejar', 'tayan...   \n",
       "197  ['mampus', 'kamu', 'admin', 'goblok', 'kebanya...   \n",
       "198  ['quoteremayaadeecbnnlu', 'yang', 'bego', 'bon...   \n",
       "199  ['astaghfirullooh', 'ngikut', 'sunnah', 'diang...   \n",
       "\n",
       "                                    stopword_tokenized  \\\n",
       "195  ['arab', 'modernisasi', 'ulama', 'provokator',...   \n",
       "196  ['ah', 'in', 'ma', 'sinetron', 'kejar', 'tayan...   \n",
       "197  ['mampus', 'admin', 'goblok', 'kebanyakan', 'm...   \n",
       "198  ['quoteremayaadeecbnnlu', 'bego', 'bong', 'gak...   \n",
       "199  ['astaghfirullooh', 'ngikut', 'sunnah', 'diang...   \n",
       "\n",
       "                                       lemmatized_text  \n",
       "195  arab modernisasi ulama provokator sara tahan g...  \n",
       "196  ah in ma sinetron kejar tayang ad istilah gant...  \n",
       "197  mampus admin goblok kebanyakan micin nangis da...  \n",
       "198  quoteremayaadeecbnnlu bego bong gak bilang aho...  \n",
       "199  astaghfirullooh ngikut sunnah dianggap tolol a...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+|$[0-9]+|\\S')\n",
    "df['tokenized_text'] = df['original_text'].apply(tokenizer.tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    txt_stopword = pd.read_csv('../resource/stopword.txt', names=['stopword'], header=None)\n",
    "    stop_words = stopwords.words('indonesian')\n",
    "    stop_words.extend(txt_stopword[\"stopword\"][0].split('\\n'))\n",
    "    stop_words.extend(['nya','yaaa','ya','nyaa','nyaaa','msh','nih'])\n",
    "    sentence = text\n",
    "    result = []\n",
    "    for word in sentence:\n",
    "        if word not in stop_words:\n",
    "            result.append(word)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stopword_tokenized'] = df['tokenized_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "\n",
    "# factory = StemmerFactory()\n",
    "# stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opsi Pertama: Melakukan stemming dan meReturn hasilnya dengan join \n",
    "# def stemmingWithJoin(konten):\n",
    "#     do = []\n",
    "#     for w in konten:\n",
    "#         dt = stemmer.stem(w)\n",
    "#         do.append(dt)\n",
    "    \n",
    "#     d_clean = []\n",
    "#     d_clean = \" \".join(do)\n",
    "#     return d_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['stemming_text'] = df['stopword_tokenized'].apply(stemmingWithJoin)\n",
    "# df['stemming_text'].iloc[759]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\AdmiN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AdmiN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk lemmatisasi\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # word_list = word_tokenize(text)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in text])\n",
    "    return lemmatized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menerapkan fungsi lemmatisasi ke kolom original_text\n",
    "df['lemmatized_text'] = df['stopword_tokenized'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       original_text  \\\n",
      "0  basherrl heh kontol jan sok pemes kamu di rp m...   \n",
      "1  kontol mana kontol memek ganas mencari im comi...   \n",
      "2  quoteadopt rapeafaacebbpatahkan kntolnyann mad...   \n",
      "3  ihh badan nya laki banget ya apalagi pantat pa...   \n",
      "4  smuterpe srp ngghh aghh fasterr pleasehh entot...   \n",
      "\n",
      "                                     lemmatized_text  \n",
      "0  basherrl heh kontol jan sok pemes rp muka kek ...  \n",
      "1  kontol kontol memek ganas mencari im coming ba...  \n",
      "2  quoteadopt rapeafaacebbpatahkan kntolnyann mad...  \n",
      "3  ihh badan laki banget pantat paha kakinya upps...  \n",
      "4  smuterpe srp ngghh aghh fasterr pleasehh entot...  \n"
     ]
    }
   ],
   "source": [
    "print(df[['original_text', 'lemmatized_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export File Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/preprocessing_200.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
